# ST-SiameseNet: Validating Trajectory Authenticity

When we modify a trajectory, how do we know the result still looks like a real taxi trip? FAMAIL uses a **Siamese LSTM neural network** — called ST-SiameseNet — that has been trained to determine whether two trajectory sequences were generated by the same driver.

---

## Architecture Overview

The discriminator takes two trajectories as input and outputs a similarity score between 0 and 1:

```
                          ┌──────────────┐
Original Trajectory τ  ──→│              │
                          │   Shared     │
                          │   LSTM       │──→  Compare  ──→  Similarity
                          │   Encoder    │        ↑          Score ∈ [0, 1]
Modified Trajectory τ′ ──→│              │        │
                          └──────────────┘        │
                          (shared weights)    MLP + Sigmoid
```

### Input

Each trajectory is a sequence of spatiotemporal states: grid coordinates, time of day, and day of week.

### Encoding

A bidirectional LSTM with **shared weights** processes both trajectories into fixed-length vector representations. Sharing weights ensures that both trajectories are embedded into the same feature space, enabling meaningful comparison.

### Comparison

The two representations are compared via a multi-layer perceptron (MLP) that outputs $P(\text{same driver})$.

### Output

- Score $\approx 1.0$: The modified trajectory is indistinguishable from the original — the edit preserves the driver's behavioral signature.
- Score $\approx 0.0$: The modification has altered the trajectory so much that it no longer resembles the original driver's behavior.

---

## Role in the Optimization

During trajectory modification, the discriminator is **frozen** — its parameters are not updated. However, gradients flow *through* the discriminator back to the modified trajectory, allowing the optimizer to learn which modifications preserve driver-consistent behavior.

The fidelity score acts as a **regularization term** in the [objective function](objective-function.md):

$$\mathcal{L} = \alpha_1 \cdot F_{\text{spatial}} + \alpha_2 \cdot F_{\text{causal}} + \alpha_3 \cdot F_{\text{fidelity}}$$

This prevents the optimizer from making unrealistically large location shifts just to improve fairness metrics. The discriminator anchors the modifications to behavioral reality.

---

## Why a Siamese Architecture?

Traditional classifiers answer "is this trajectory real?" — a question that requires defining what "real" means in absolute terms. The Siamese architecture instead answers a relative question: **"do these two trajectories look like they came from the same driver?"**

This relative framing is ideal for FAMAIL because:

- We always have the original trajectory as a reference point
- We care about the *degree of change*, not absolute quality
- The shared encoder naturally learns driver-invariant features

!!! info "Pre-trained and frozen"
    ST-SiameseNet is trained once on the full trajectory dataset, then frozen during the optimization loop. Only the trajectory pickup locations are modified — the discriminator provides gradient signal but is never updated.

---
